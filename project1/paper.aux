\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{Sutton1988}
\citation{Sutton:1998:IRL:551283}
\citation{KLMSurvey}
\citation{Szepesvari:2010:ARL:1855083}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\newlabel{sec:introduction}{{1}{1}{Introduction}{section.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Background}{1}{subsection.1.1}\protected@file@percent }
\newlabel{subsec:background}{{1.1}{1}{Background}{subsection.1.1}{}}
\newlabel{eqn:1}{{1}{1}{Background}{equation.1.1}{}}
\newlabel{eqn:2}{{2}{1}{Background}{equation.1.2}{}}
\newlabel{eqn:3}{{3}{2}{Background}{equation.1.3}{}}
\newlabel{eqn:4}{{4}{2}{Background}{equation.1.4}{}}
\newlabel{eqn:5}{{5}{2}{Background}{equation.1.5}{}}
\newlabel{eqn:6}{{6}{2}{Background}{equation.1.6}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Value-state prediction with TD($\lambda $)}}{2}{algorithm.1}\protected@file@percent }
\newlabel{alg:1}{{1}{2}{Background}{algorithm.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Random Walk}{2}{subsection.1.2}\protected@file@percent }
\newlabel{subsec:randomwalk}{{1.2}{2}{Random Walk}{subsection.1.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces A bounded random walk generator used in Sutton's original paper. All episodes start in state $D$. At each time step, walk has equal probability of either moving left or right. Episode ends when walk reaches either $A$ or $G$. In case of episode terminating in $G$, +1 reward is received; otherwise, reward is zero.}}{3}{figure.1}\protected@file@percent }
\newlabel{fig:1}{{1}{3}{A bounded random walk generator used in Sutton's original paper. All episodes start in state $D$. At each time step, walk has equal probability of either moving left or right. Episode ends when walk reaches either $A$ or $G$. In case of episode terminating in $G$, +1 reward is received; otherwise, reward is zero}{figure.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Methods}{3}{section.2}\protected@file@percent }
\newlabel{sec:methods}{{2}{3}{Methods}{section.2}{}}
\bibstyle{unsrt}
\bibdata{references}
\newlabel{fig:fig2}{{3}{4}{Results and Discussion}{section.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Replication of Figures 3, 4 and 5 from Sutton's original paper. In the left, average error on random walk problem under repeated presentations. In the center, average error on random walk problem after 10 episodes for different values of $\alpha $ and $\gamma $. In the right, average error at best $\alpha $ on random walk problem for different values of $\gamma $.}}{4}{figure.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}Results and Discussion}{4}{section.3}\protected@file@percent }
\newlabel{sec:results}{{3}{4}{Results and Discussion}{section.3}{}}
\bibcite{Sutton1988}{1}
\bibcite{Sutton:1998:IRL:551283}{2}
\bibcite{KLMSurvey}{3}
\bibcite{Szepesvari:2010:ARL:1855083}{4}
\@writefile{toc}{\contentsline {section}{\numberline {4}Conclusion}{5}{section.4}\protected@file@percent }
\newlabel{sec:conclusion}{{4}{5}{Conclusion}{section.4}{}}
